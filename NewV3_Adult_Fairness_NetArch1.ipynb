{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title-cell",
      "metadata": {
        "id": "title-cell"
      },
      "source": [
        "# NewV2 Adult Fairness NetArch1\n",
        "\n",
        "This notebook has been updated to include two evaluation approaches:\n",
        "\n",
        "1. **k‑Fold Cross Validation:** For each fold, the same train/test split is used for both the baseline‑compressed and QAT models. The results are then aggregated across all folds.\n",
        "2. **Fixed Split Evaluation:** A single fixed split (using, e.g., the 0th fold) is used to train and evaluate both models for a fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vEx3Eg3NSvGV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEx3Eg3NSvGV",
        "outputId": "78144146-f01f-4022-fd68-406356fcba70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install fairlearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.quantization import quantize_dynamic, QConfig, prepare_qat, convert\n",
        "from torch.quantization.fake_quantize import FakeQuantize\n",
        "from torch.quantization.observer import MovingAverageMinMaxObserver\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from fairlearn.metrics import MetricFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    selection_rate,\n",
        "    true_positive_rate,\n",
        "    false_positive_rate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vdzwMJ6cmP8H",
      "metadata": {
        "id": "vdzwMJ6cmP8H"
      },
      "source": [
        "##Code Persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ENXhqplymOew",
      "metadata": {
        "id": "ENXhqplymOew"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_path):\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "\"\"\"\n",
        "def save_values_to_txt(data, filename):\n",
        "  with open(filename, 'a') as f:\n",
        "      for entry in data:\n",
        "          for key, value in entry.items():\n",
        "              f.write(f'{key}: {value}\\n')\n",
        "          f.write('\\n')\n",
        "  print(f\"Data appended to {filename}\")\n",
        "\"\"\"\n",
        "def save_values_to_txt(data, filename):\n",
        "    if isinstance(data, dict):\n",
        "        data = [data]\n",
        "    with open(filename, 'a') as f:\n",
        "        for entry in data:\n",
        "            for key, value in entry.items():\n",
        "                f.write(f'{key}: {value}\\n')\n",
        "            f.write('\\n')\n",
        "    print(f\"Data appended to {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports-seed",
      "metadata": {
        "id": "imports-seed"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oetFnOHYlXpQ",
      "metadata": {
        "id": "oetFnOHYlXpQ"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "data-loading",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "data-loading",
        "outputId": "b641b1f2-260e-4461-92e2-b96932c91ab2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-54-4328390a73c8>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = y.replace({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1}).astype(int)\n"
          ]
        }
      ],
      "source": [
        "def load_your_dataset():\n",
        "    adult = fetch_ucirepo(id=2)\n",
        "    X = adult.data.features\n",
        "    y = adult.data.targets\n",
        "    y = y.replace({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1}).astype(int)\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y.values.ravel())\n",
        "    X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_np = scaler.fit_transform(X_encoded).astype(np.float32)\n",
        "    y_np = np.array(y).astype(np.int64)\n",
        "\n",
        "    A_np = X[\"sex\"].values\n",
        "\n",
        "    return X_np, y_np, A_np\n",
        "\n",
        "X_np, y_np, A_np = load_your_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGy0GFfwfT90",
      "metadata": {
        "id": "qGy0GFfwfT90"
      },
      "source": [
        "## Fairness Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qAqqn7W5fXD6",
      "metadata": {
        "id": "qAqqn7W5fXD6"
      },
      "source": [
        "* Statistical Parity Difference: Closer to 0 is better. 0 means no bias.\n",
        "* Average Odds Difference: 0 is ideal, indicating no discrimination.\n",
        "* Disparate Impact: Aim for 1. Values close to 1 indicate fairness.\n",
        "* Theil Index: Lower is better. 0 means perfect equality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QrCSQTx7fR8x",
      "metadata": {
        "id": "QrCSQTx7fR8x"
      },
      "outputs": [],
      "source": [
        "def calculate_statistical_parity_difference(y_true, y_pred, A_test):\n",
        "    sr = lambda y_true, y_pred: selection_rate(y_true, y_pred)\n",
        "    mfm = MetricFrame(metrics=sr, y_true=y_test, y_pred=y_pred, sensitive_features=A_test)\n",
        "    return mfm.difference(method='between_groups')\n",
        "\n",
        "def calculate_average_odds_difference(y_true, y_pred, A_test):\n",
        "    unique_labels = np.unique(y_true)\n",
        "    if len(unique_labels) == 2:\n",
        "        pos_label = unique_labels[1]\n",
        "    else:\n",
        "        raise ValueError(\"y_true should have exactly two unique values for binary classification\")\n",
        "\n",
        "    tpr = lambda y_true, y_pred: true_positive_rate(y_true, y_pred, pos_label=pos_label)\n",
        "    fpr = lambda y_true, y_pred: false_positive_rate(y_true, y_pred, pos_label=pos_label)\n",
        "    average_odds = lambda y_true, y_pred: (tpr(y_true, y_pred) + fpr(y_true, y_pred)) / 2\n",
        "\n",
        "    mf = MetricFrame(metrics=average_odds,\n",
        "                     y_true=y_true,\n",
        "                     y_pred=y_pred,\n",
        "                     sensitive_features=A_test)\n",
        "    return mf.difference(method='between_groups')\n",
        "\n",
        "def calculate_disparate_impact(y_true, y_pred, A_test):\n",
        "    sr = lambda y_true, y_pred: selection_rate(y_true, y_pred)\n",
        "    mf = MetricFrame(metrics=sr, y_true=y_true, y_pred=y_pred, sensitive_features=A_test)\n",
        "    return mf.ratio(method='between_groups')\n",
        "\n",
        "def calculate_theil_index(y_true, y_pred):\n",
        "    actual_pos = np.mean(y_true == 1)\n",
        "    pred_pos = np.mean(y_pred == 1)\n",
        "\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    actual_entropy = -(actual_pos * np.log2(actual_pos + epsilon) + (1 - actual_pos) * np.log2(1 - actual_pos + epsilon))\n",
        "    pred_entropy = -(pred_pos * np.log2(pred_pos + epsilon) + (1 - pred_pos) * np.log2(1 - pred_pos + epsilon))\n",
        "\n",
        "    theil_index = pred_entropy - actual_entropy\n",
        "\n",
        "    #mf = MetricFrame(metrics=sr, y_true=y_true, y_pred=y_pred, sensitive_features=A_test)\n",
        "    #mf.difference(method='between_groups')\n",
        "    return theil_index\n",
        "    \"\"\"\n",
        "    actual_pos = np.mean(y_true == 1)\n",
        "    pred_pos = np.mean(y_pred == 1)\n",
        "\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    # KL Divergence Calculation (non-negative)\n",
        "    actual_entropy = -(actual_pos * np.log2(actual_pos + epsilon) + (1 - actual_pos) * np.log2(1 - actual_pos + epsilon))\n",
        "    pred_entropy = -(pred_pos * np.log2(pred_pos + epsilon) + (1 - pred_pos) * np.log2(1 - pred_pos + epsilon))\n",
        "\n",
        "    theil_index = np.abs(pred_entropy - actual_entropy)  # Use absolute difference to avoid negatives\n",
        "    return theil_index\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BodvsNNjdMf0",
      "metadata": {
        "id": "BodvsNNjdMf0"
      },
      "source": [
        "##Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde4U484dHls",
      "metadata": {
        "id": "fde4U484dHls"
      },
      "outputs": [],
      "source": [
        "n_input = X_np.shape[1]\n",
        "\n",
        "class NetArch1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(n_input, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(128)\n",
        "        self.layernorm2 = nn.LayerNorm(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layernorm1(F.relu(self.fc1(x)))\n",
        "        x = self.layernorm2(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class NetArch2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class NetArch3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = F.sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3qMDI31QdSBD",
      "metadata": {
        "id": "3qMDI31QdSBD"
      },
      "source": [
        "## QAT Compatible Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y4am0xSSdOfi",
      "metadata": {
        "id": "y4am0xSSdOfi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.quantization\n",
        "\n",
        "n_input = X_np.shape[1]\n",
        "\n",
        "class QATArch1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.fc1 = nn.Linear(n_input, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "        self.layernorm1 = nn.LayerNorm(128)\n",
        "        self.layernorm2 = nn.LayerNorm(64)\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.layernorm1(F.relu(self.fc1(x)))\n",
        "        x = self.layernorm2(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        x = self.dequant(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class QATArch2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.dequant(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class QATArch3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.dequant(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "helper-functions",
      "metadata": {
        "id": "helper-functions"
      },
      "outputs": [],
      "source": [
        "def dynamic_compress_model(model_path):\n",
        "    model = NetArch1()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    compressed_model = quantize_dynamic(\n",
        "        model=model,\n",
        "        qconfig_spec={torch.nn.Linear},\n",
        "        dtype=torch.qint8\n",
        "    )\n",
        "    return compressed_model\n",
        "\n",
        "def prepare_model_for_qat(model):\n",
        "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "    model = torch.quantization.prepare_qat(model)\n",
        "    return model\n",
        "\n",
        "def convert_qat_model(model):\n",
        "    model = torch.quantization.convert(model.eval())\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_k_fold_split(X, y,A, k, num_splits=5):\n",
        "    indices = np.arange(len(X))\n",
        "    fold_size = len(X) // num_splits\n",
        "\n",
        "    start = k * fold_size\n",
        "    end = start + fold_size if k != num_splits - 1 else len(X)\n",
        "\n",
        "    test_idx = indices[start:end]\n",
        "    train_idx = np.concatenate([indices[:start], indices[end:]])\n",
        "\n",
        "    return X[train_idx], y[train_idx], A[train_idx], X[test_idx], y[test_idx], A[test_idx]\n",
        "\n",
        "\n",
        "def train_baseline_model(X_train, y_train, fold, num_epochs=10, batch_size=64):\n",
        "  model = NetArch1()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "  train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "      for batch_X, batch_y in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(batch_X)\n",
        "          loss = criterion(outputs, batch_y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  y_true, y_pred = [], []\n",
        "  with torch.no_grad():\n",
        "      for batch_X, batch_y in train_loader:\n",
        "          outputs = model(batch_X)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          y_true.extend(batch_y.numpy())\n",
        "          y_pred.extend(predicted.numpy())\n",
        "\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "  print(f\"Fold {fold + 1}: Train F1 Score = {f1:.4f}\")\n",
        "\n",
        "\n",
        "  model_path = f\"model_fold{fold}.pkl\"\n",
        "  save_model(model, model_path)\n",
        "\n",
        "  return model\n",
        "\n",
        "def train_qat_model(X_train, y_train, fold, num_epochs=10, batch_size=64):\n",
        "    model = QATArch1()\n",
        "    model = prepare_model_for_qat(model)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_X.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    quantized_model = convert_qat_model(model)\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            outputs = quantized_model(batch_X)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(batch_y.numpy())\n",
        "            y_pred.extend(predicted.numpy())\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"Fold {fold + 1}: Train F1 Score (QAT) = {f1:.4f}\")\n",
        "\n",
        "    model_path = f\"qat_model_fold{fold}.pkl\"\n",
        "    save_model(quantized_model, model_path)\n",
        "\n",
        "    return quantized_model\n",
        "\n",
        "\n",
        "def evaluate_baseline_model(model, X_test, y_test, A_test):\n",
        "    output = model.forward(torch.FloatTensor(X_test))\n",
        "    _, y_pred = torch.max(output, dim=1)\n",
        "\n",
        "    y_pred = pd.Series(y_pred.detach().numpy())\n",
        "    y_test = pd.Series(y_test)\n",
        "\n",
        "    mf1 = MetricFrame(metrics=f1_score, y_true=y_test, y_pred=y_pred, sensitive_features=A_test)\n",
        "\n",
        "    baseline_metrics = {\n",
        "        \"Baseline Statistical Parity Difference\": round(calculate_statistical_parity_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Baseline Average Odds Difference\": round(calculate_average_odds_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Baseline Disparate Impact\": round(calculate_disparate_impact(y_test, y_pred, A_test), 3),\n",
        "        \"Baseline Theil Index\": round(calculate_theil_index(y_test, y_pred),3),\n",
        "        \"Baseline F1 Score\": round(f1_score(y_test, y_pred),3)\n",
        "    }\n",
        "\n",
        "    return baseline_metrics\n",
        "\n",
        "def evaluate_qat_model(model, X_test, y_test, A_test):\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    nan_mask = np.isnan(X_test)\n",
        "    if nan_mask.any():\n",
        "        col_means = np.nanmean(X_test, axis=0)\n",
        "        X_test[nan_mask] = col_means[nan_mask[0]]\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(X_test_tensor)\n",
        "        _, y_pred = torch.max(output, dim=1)\n",
        "\n",
        "    y_pred_np = y_pred.cpu().numpy()\n",
        "\n",
        "    qat_metrics = {\n",
        "        \"QAT Statistical Parity Difference\": round(calculate_statistical_parity_difference(y_test, y_pred_np, A_test), 3),\n",
        "        \"QAT Average Odds Difference\": round(calculate_average_odds_difference(y_test, y_pred_np, A_test), 3),\n",
        "        \"QAT Disparate Impact\": round(calculate_disparate_impact(y_test, y_pred_np, A_test), 3),\n",
        "        \"QAT Theil Index\": round(calculate_theil_index(y_test, y_pred_np), 3),\n",
        "        \"QAT F1 Score\": round(f1_score(y_test, y_pred_np), 3),\n",
        "        \"F1 Score\": round(f1_score(y_test, y_pred_np), 3)\n",
        "    }\n",
        "\n",
        "    return qat_metrics\n",
        "\n",
        "def evaluate_compressed_model(model, X_test, y_test, A_test):\n",
        "    output = model(torch.FloatTensor(X_test))\n",
        "    _, y_pred = torch.max(output, dim=1)\n",
        "\n",
        "    y_pred = pd.Series(y_pred.detach().numpy())\n",
        "    y_test = pd.Series(y_test)\n",
        "\n",
        "    mf = MetricFrame(metrics=f1_score, y_true=y_test, y_pred=y_pred, sensitive_features=A_test)\n",
        "\n",
        "    compressed_metrics = {\n",
        "        \"Compressed Statistical Parity Difference\": round(calculate_statistical_parity_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Compressed Average Odds Difference\": round(calculate_average_odds_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Compressed Disparate Impact\": round(calculate_disparate_impact(y_test, y_pred, A_test), 3),\n",
        "        \"Compressed Theil Index\": round(calculate_theil_index(y_test, y_pred), 3),\n",
        "        \"Compressed F1 Score\": round(f1_score(y_test, y_pred), 3),\n",
        "    }\n",
        "\n",
        "    return compressed_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "av1ZTFC200mE",
      "metadata": {
        "id": "av1ZTFC200mE"
      },
      "source": [
        "### k‑Fold Cross Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kfold-crossvalidation",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfold-crossvalidation",
        "outputId": "45934143-aa4f-421c-b158-7bdd31277df4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-54-4328390a73c8>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = y.replace({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1}).astype(int)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing fold 1/10\n",
            "Fold 1: Train F1 Score = 0.7180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Train F1 Score (QAT) = 0.7183\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.172), 'Baseline Average Odds Difference': np.float64(0.087), 'Baseline Disparate Impact': np.float64(0.329), 'Baseline Theil Index': np.float64(-0.077), 'Baseline F1 Score': 0.653}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.191), 'Compressed Average Odds Difference': np.float64(0.115), 'Compressed Disparate Impact': np.float64(0.305), 'Compressed Theil Index': np.float64(-0.054), 'Compressed F1 Score': 0.657}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.174), 'QAT Average Odds Difference': np.float64(0.083), 'QAT Disparate Impact': np.float64(0.337), 'QAT Theil Index': np.float64(-0.066), 'QAT F1 Score': 0.673, 'F1 Score': 0.673}\n",
            "\n",
            "Processing fold 2/10\n",
            "Fold 2: Train F1 Score = 0.7182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2: Train F1 Score (QAT) = 0.7096\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.159), 'Baseline Average Odds Difference': np.float64(0.036), 'Baseline Disparate Impact': np.float64(0.38), 'Baseline Theil Index': np.float64(-0.054), 'Baseline F1 Score': 0.666}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.185), 'Compressed Average Odds Difference': np.float64(0.04), 'Compressed Disparate Impact': np.float64(0.384), 'Compressed Theil Index': np.float64(0.01), 'Compressed F1 Score': 0.682}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.143), 'QAT Average Odds Difference': np.float64(0.028), 'QAT Disparate Impact': np.float64(0.389), 'QAT Theil Index': np.float64(-0.09), 'QAT F1 Score': 0.665, 'F1 Score': 0.665}\n",
            "\n",
            "Processing fold 3/10\n",
            "Fold 3: Train F1 Score = 0.7223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3: Train F1 Score (QAT) = 0.6999\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.185), 'Baseline Average Odds Difference': np.float64(0.085), 'Baseline Disparate Impact': np.float64(0.29), 'Baseline Theil Index': np.float64(-0.074), 'Baseline F1 Score': 0.657}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.212), 'Compressed Average Odds Difference': np.float64(0.084), 'Compressed Disparate Impact': np.float64(0.304), 'Compressed Theil Index': np.float64(-0.01), 'Compressed F1 Score': 0.676}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.175), 'QAT Average Odds Difference': np.float64(0.069), 'QAT Disparate Impact': np.float64(0.277), 'QAT Theil Index': np.float64(-0.107), 'QAT F1 Score': 0.646, 'F1 Score': 0.646}\n",
            "\n",
            "Processing fold 4/10\n",
            "Fold 4: Train F1 Score = 0.7301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4: Train F1 Score (QAT) = 0.7210\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.18), 'Baseline Average Odds Difference': np.float64(0.063), 'Baseline Disparate Impact': np.float64(0.365), 'Baseline Theil Index': np.float64(-0.028), 'Baseline F1 Score': 0.68}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.213), 'Compressed Average Odds Difference': np.float64(0.092), 'Compressed Disparate Impact': np.float64(0.349), 'Compressed Theil Index': np.float64(0.027), 'Compressed F1 Score': 0.69}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.186), 'QAT Average Odds Difference': np.float64(0.081), 'QAT Disparate Impact': np.float64(0.341), 'QAT Theil Index': np.float64(-0.035), 'QAT F1 Score': 0.68, 'F1 Score': 0.68}\n",
            "\n",
            "Processing fold 5/10\n",
            "Fold 5: Train F1 Score = 0.7255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5: Train F1 Score (QAT) = 0.7123\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.185), 'Baseline Average Odds Difference': np.float64(0.072), 'Baseline Disparate Impact': np.float64(0.323), 'Baseline Theil Index': np.float64(-0.055), 'Baseline F1 Score': 0.692}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.219), 'Compressed Average Odds Difference': np.float64(0.103), 'Compressed Disparate Impact': np.float64(0.305), 'Compressed Theil Index': np.float64(-0.001), 'Compressed F1 Score': 0.682}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.164), 'QAT Average Odds Difference': np.float64(0.059), 'QAT Disparate Impact': np.float64(0.34), 'QAT Theil Index': np.float64(-0.09), 'QAT F1 Score': 0.681, 'F1 Score': 0.681}\n",
            "\n",
            "Processing fold 6/10\n",
            "Fold 6: Train F1 Score = 0.7221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 6: Train F1 Score (QAT) = 0.7100\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.199), 'Baseline Average Odds Difference': np.float64(0.089), 'Baseline Disparate Impact': np.float64(0.288), 'Baseline Theil Index': np.float64(-0.051), 'Baseline F1 Score': 0.681}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.222), 'Compressed Average Odds Difference': np.float64(0.095), 'Compressed Disparate Impact': np.float64(0.284), 'Compressed Theil Index': np.float64(-0.01), 'Compressed F1 Score': 0.678}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.175), 'QAT Average Odds Difference': np.float64(0.061), 'QAT Disparate Impact': np.float64(0.311), 'QAT Theil Index': np.float64(-0.084), 'QAT F1 Score': 0.668, 'F1 Score': 0.668}\n",
            "\n",
            "Processing fold 7/10\n",
            "Fold 7: Train F1 Score = 0.7066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 7: Train F1 Score (QAT) = 0.7154\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.184), 'Baseline Average Odds Difference': np.float64(0.118), 'Baseline Disparate Impact': np.float64(0.284), 'Baseline Theil Index': np.float64(-0.09), 'Baseline F1 Score': 0.653}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.215), 'Compressed Average Odds Difference': np.float64(0.131), 'Compressed Disparate Impact': np.float64(0.295), 'Compressed Theil Index': np.float64(-0.019), 'Compressed F1 Score': 0.671}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.179), 'QAT Average Odds Difference': np.float64(0.089), 'QAT Disparate Impact': np.float64(0.339), 'QAT Theil Index': np.float64(-0.059), 'QAT F1 Score': 0.659, 'F1 Score': 0.659}\n",
            "\n",
            "Processing fold 8/10\n",
            "Fold 8: Train F1 Score = 0.7155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 8: Train F1 Score (QAT) = 0.7184\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.179), 'Baseline Average Odds Difference': np.float64(0.092), 'Baseline Disparate Impact': np.float64(0.29), 'Baseline Theil Index': np.float64(-0.08), 'Baseline F1 Score': 0.664}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.189), 'Compressed Average Odds Difference': np.float64(0.095), 'Compressed Disparate Impact': np.float64(0.289), 'Compressed Theil Index': np.float64(-0.06), 'Compressed F1 Score': 0.671}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.187), 'QAT Average Odds Difference': np.float64(0.088), 'QAT Disparate Impact': np.float64(0.303), 'QAT Theil Index': np.float64(-0.055), 'QAT F1 Score': 0.673, 'F1 Score': 0.673}\n",
            "\n",
            "Processing fold 9/10\n",
            "Fold 9: Train F1 Score = 0.7040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 9: Train F1 Score (QAT) = 0.7172\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.129), 'Baseline Average Odds Difference': np.float64(0.023), 'Baseline Disparate Impact': np.float64(0.398), 'Baseline Theil Index': np.float64(-0.122), 'Baseline F1 Score': 0.649}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.152), 'Compressed Average Odds Difference': np.float64(0.032), 'Compressed Disparate Impact': np.float64(0.396), 'Compressed Theil Index': np.float64(-0.06), 'Compressed F1 Score': 0.655}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.167), 'QAT Average Odds Difference': np.float64(0.046), 'QAT Disparate Impact': np.float64(0.341), 'QAT Theil Index': np.float64(-0.064), 'QAT F1 Score': 0.666, 'F1 Score': 0.666}\n",
            "\n",
            "Processing fold 10/10\n",
            "Fold 10: Train F1 Score = 0.7324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 10: Train F1 Score (QAT) = 0.7040\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.195), 'Baseline Average Odds Difference': np.float64(0.095), 'Baseline Disparate Impact': np.float64(0.33), 'Baseline Theil Index': np.float64(-0.022), 'Baseline F1 Score': 0.676}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.216), 'Compressed Average Odds Difference': np.float64(0.123), 'Compressed Disparate Impact': np.float64(0.318), 'Compressed Theil Index': np.float64(0.01), 'Compressed F1 Score': 0.673}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.16), 'QAT Average Odds Difference': np.float64(0.075), 'QAT Disparate Impact': np.float64(0.319), 'QAT Theil Index': np.float64(-0.11), 'QAT F1 Score': 0.656, 'F1 Score': 0.656}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X, y, A = load_your_dataset()\n",
        "num_splits = 10\n",
        "\n",
        "baseline_fold_metrics = []\n",
        "compressed_fold_metrics = []\n",
        "qat_fold_metrics = []\n",
        "\n",
        "for k in range(num_splits):\n",
        "    print(f\"\\nProcessing fold {k + 1}/{num_splits}\")\n",
        "\n",
        "    X_train, y_train, A_train, X_test, y_test, A_test = get_k_fold_split(X, y, A, k, num_splits)\n",
        "\n",
        "    baseline_model = train_baseline_model(X_train, y_train, k)\n",
        "    baseline_eval = evaluate_baseline_model(baseline_model, X_test, y_test, A_test)\n",
        "    model_path = f\"model_fold{k}.pkl\"\n",
        "\n",
        "    compressed_model = dynamic_compress_model(model_path)\n",
        "    compressed_eval = evaluate_compressed_model(compressed_model, X_test, y_test, A_test)\n",
        "\n",
        "    qat_model = train_qat_model(X_train, y_train, k)\n",
        "    qat_eval = evaluate_qat_model(qat_model, X_test, y_test, A_test)\n",
        "\n",
        "    baseline_fold_metrics.append(baseline_eval)\n",
        "    compressed_fold_metrics.append(compressed_eval)\n",
        "    qat_fold_metrics.append(qat_eval)\n",
        "\n",
        "    print(f\"Baseline Eval: {baseline_eval}\")\n",
        "    print(f\"Compressed Eval: {compressed_eval}\")\n",
        "    print(f\"QAT Eval: {qat_eval}\")\n",
        "\n",
        "baseline_df = pd.DataFrame(baseline_fold_metrics)\n",
        "compressed_df = pd.DataFrame(compressed_fold_metrics)\n",
        "qat_df = pd.DataFrame(qat_fold_metrics)\n",
        "\n",
        "\n",
        "baseline_df.to_csv(\"baseline_metrics.csv\", index=True, float_format=\"%.3f\")\n",
        "compressed_df.to_csv(\"compressed_metrics.csv\", index=True, float_format=\"%.3f\")\n",
        "qat_df.to_csv(\"qat_metrics.csv\", index=True, float_format=\"%.3f\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VpVaPNTKKNk9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpVaPNTKKNk9",
        "outputId": "eeb076a4-9531-461a-c459-e9b7df5d854a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Baseline Statistical Parity Difference  Baseline Average Odds Difference  \\\n",
            "0                                   0.188                             0.103   \n",
            "1                                   0.162                             0.035   \n",
            "2                                   0.207                             0.104   \n",
            "3                                   0.169                             0.046   \n",
            "4                                   0.148                             0.038   \n",
            "5                                   0.199                             0.102   \n",
            "6                                   0.194                             0.110   \n",
            "7                                   0.178                             0.113   \n",
            "8                                   0.187                             0.086   \n",
            "9                                   0.184                             0.095   \n",
            "\n",
            "   Baseline Disparate Impact  Baseline Theil Index  Baseline F1 Score  \n",
            "0                      0.322                -0.047              0.668  \n",
            "1                      0.365                -0.058              0.679  \n",
            "2                      0.268                -0.046              0.668  \n",
            "3                      0.382                -0.040              0.677  \n",
            "4                      0.344                -0.128              0.652  \n",
            "5                      0.270                -0.063              0.690  \n",
            "6                      0.328                -0.035              0.669  \n",
            "7                      0.268                -0.100              0.656  \n",
            "8                      0.303                -0.048              0.674  \n",
            "9                      0.339                -0.039              0.679  \n"
          ]
        }
      ],
      "source": [
        "print(baseline_df)\n",
        "baseline_df.to_csv(\"baseline_metrics.csv\", index=True, float_format=\"%.3f\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9tEpQQ4eq1jL",
      "metadata": {
        "id": "9tEpQQ4eq1jL"
      },
      "outputs": [],
      "source": [
        "!zip -r colab_files.zip /content\n",
        "from google.colab import files\n",
        "files.download('colab_files.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Friedman test"
      ],
      "metadata": {
        "id": "CnVZ-31p08HU"
      },
      "id": "CnVZ-31p08HU"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ju3C_VUuzMHp"
      },
      "id": "Ju3C_VUuzMHp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}