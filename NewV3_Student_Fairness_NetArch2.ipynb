{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title-cell",
      "metadata": {
        "id": "title-cell"
      },
      "source": [
        "# NewV2 Adult Fairness NetArch2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vEx3Eg3NSvGV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEx3Eg3NSvGV",
        "outputId": "99cad436-480a-4256-d1af-f8a8252a6863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install fairlearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.quantization import quantize_dynamic, QConfig, prepare_qat, convert\n",
        "from torch.quantization.fake_quantize import FakeQuantize\n",
        "from torch.quantization.observer import MovingAverageMinMaxObserver\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from fairlearn.metrics import MetricFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    selection_rate,\n",
        "    true_positive_rate,\n",
        "    false_positive_rate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vdzwMJ6cmP8H",
      "metadata": {
        "id": "vdzwMJ6cmP8H"
      },
      "source": [
        "##Code Persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ENXhqplymOew",
      "metadata": {
        "id": "ENXhqplymOew"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_path):\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "\"\"\"\n",
        "def save_values_to_txt(data, filename):\n",
        "  with open(filename, 'a') as f:\n",
        "      for entry in data:\n",
        "          for key, value in entry.items():\n",
        "              f.write(f'{key}: {value}\\n')\n",
        "          f.write('\\n')\n",
        "  print(f\"Data appended to {filename}\")\n",
        "\"\"\"\n",
        "def save_values_to_txt(data, filename):\n",
        "    if isinstance(data, dict):\n",
        "        data = [data]\n",
        "    with open(filename, 'a') as f:\n",
        "        for entry in data:\n",
        "            for key, value in entry.items():\n",
        "                f.write(f'{key}: {value}\\n')\n",
        "            f.write('\\n')\n",
        "    print(f\"Data appended to {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports-seed",
      "metadata": {
        "id": "imports-seed"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oetFnOHYlXpQ",
      "metadata": {
        "id": "oetFnOHYlXpQ"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "data-loading",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "data-loading",
        "outputId": "45ea4056-bb47-4182-c551-2206418c64b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4328390a73c8>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = y.replace({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1}).astype(int)\n"
          ]
        }
      ],
      "source": [
        "def load_your_dataset():\n",
        "    adult = fetch_ucirepo(id=2)\n",
        "    X = adult.data.features\n",
        "    y = adult.data.targets\n",
        "    y = y.replace({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1}).astype(int)\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y.values.ravel())\n",
        "    X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_np = scaler.fit_transform(X_encoded).astype(np.float32)\n",
        "    y_np = np.array(y).astype(np.int64)\n",
        "\n",
        "    A_np = X[\"sex\"].values\n",
        "\n",
        "    return X_np, y_np, A_np\n",
        "\n",
        "X_np, y_np, A_np = load_your_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGy0GFfwfT90",
      "metadata": {
        "id": "qGy0GFfwfT90"
      },
      "source": [
        "## Fairness Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qAqqn7W5fXD6",
      "metadata": {
        "id": "qAqqn7W5fXD6"
      },
      "source": [
        "* Statistical Parity Difference: Closer to 0 is better. 0 means no bias.\n",
        "* Average Odds Difference: 0 is ideal, indicating no discrimination.\n",
        "* Disparate Impact: Aim for 1. Values close to 1 indicate fairness.\n",
        "* Theil Index: Lower is better. 0 means perfect equality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QrCSQTx7fR8x",
      "metadata": {
        "id": "QrCSQTx7fR8x"
      },
      "outputs": [],
      "source": [
        "def calculate_statistical_parity_difference(y_true, y_pred, A_test):\n",
        "    sr = lambda y_true, y_pred: selection_rate(y_true, y_pred)\n",
        "    mfm = MetricFrame(metrics=sr, y_true=y_test, y_pred=y_pred, sensitive_features=A_test)\n",
        "    return mfm.difference(method='between_groups')\n",
        "\n",
        "def calculate_average_odds_difference(y_true, y_pred, A_test):\n",
        "    unique_labels = np.unique(y_true)\n",
        "    if len(unique_labels) == 2:\n",
        "        pos_label = unique_labels[1]\n",
        "    else:\n",
        "        raise ValueError(\"y_true should have exactly two unique values for binary classification\")\n",
        "\n",
        "    tpr = lambda y_true, y_pred: true_positive_rate(y_true, y_pred, pos_label=pos_label)\n",
        "    fpr = lambda y_true, y_pred: false_positive_rate(y_true, y_pred, pos_label=pos_label)\n",
        "    average_odds = lambda y_true, y_pred: (tpr(y_true, y_pred) + fpr(y_true, y_pred)) / 2\n",
        "\n",
        "    mf = MetricFrame(metrics=average_odds,\n",
        "                     y_true=y_true,\n",
        "                     y_pred=y_pred,\n",
        "                     sensitive_features=A_test)\n",
        "    return mf.difference(method='between_groups')\n",
        "\n",
        "def calculate_disparate_impact(y_true, y_pred, A_test):\n",
        "    sr = lambda y_true, y_pred: selection_rate(y_true, y_pred)\n",
        "    mf = MetricFrame(metrics=sr, y_true=y_true, y_pred=y_pred, sensitive_features=A_test)\n",
        "    return mf.ratio(method='between_groups')\n",
        "\n",
        "def calculate_theil_index(y_true, y_pred):\n",
        "    actual_pos = np.mean(y_true == 1)\n",
        "    pred_pos = np.mean(y_pred == 1)\n",
        "\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    actual_entropy = -(actual_pos * np.log2(actual_pos + epsilon) + (1 - actual_pos) * np.log2(1 - actual_pos + epsilon))\n",
        "    pred_entropy = -(pred_pos * np.log2(pred_pos + epsilon) + (1 - pred_pos) * np.log2(1 - pred_pos + epsilon))\n",
        "\n",
        "    theil_index = pred_entropy - actual_entropy\n",
        "    return theil_index\n",
        "def theil_index(values):\n",
        "    values = np.array(values)\n",
        "    mean_val = np.mean(values)\n",
        "    if mean_val == 0:\n",
        "        return 0\n",
        "    theil = np.mean((values / mean_val) * np.log(values / mean_val + 1e-10))\n",
        "    return theil\n",
        "def theil_by_group(values, groups):\n",
        "    df = pd.DataFrame({'value': values, 'group': groups})\n",
        "    return df.groupby('group')['value'].apply(theil_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BodvsNNjdMf0",
      "metadata": {
        "id": "BodvsNNjdMf0"
      },
      "source": [
        "##Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde4U484dHls",
      "metadata": {
        "id": "fde4U484dHls"
      },
      "outputs": [],
      "source": [
        "n_input = X_np.shape[1]\n",
        "\n",
        "class NetArch1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(n_input, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(128)\n",
        "        self.layernorm2 = nn.LayerNorm(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layernorm1(F.relu(self.fc1(x)))\n",
        "        x = self.layernorm2(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class NetArch2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class NetArch3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = F.sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3qMDI31QdSBD",
      "metadata": {
        "id": "3qMDI31QdSBD"
      },
      "source": [
        "## QAT Compatible Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y4am0xSSdOfi",
      "metadata": {
        "id": "y4am0xSSdOfi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.quantization\n",
        "\n",
        "n_input = X_np.shape[1]\n",
        "\n",
        "class QATArch1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.fc1 = nn.Linear(n_input, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "        self.layernorm1 = nn.LayerNorm(128)\n",
        "        self.layernorm2 = nn.LayerNorm(64)\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.layernorm1(F.relu(self.fc1(x)))\n",
        "        x = self.layernorm2(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        x = self.dequant(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class QATArch2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.dequant(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class QATArch3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.fc1 = nn.Linear(n_input, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.dequant(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "helper-functions",
      "metadata": {
        "id": "helper-functions"
      },
      "outputs": [],
      "source": [
        "def dynamic_compress_model(model_path):\n",
        "    model = NetArch2()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    compressed_model = quantize_dynamic(\n",
        "        model=model,\n",
        "        qconfig_spec={torch.nn.Linear},\n",
        "        dtype=torch.qint8\n",
        "    )\n",
        "    return compressed_model\n",
        "\n",
        "def prepare_model_for_qat(model):\n",
        "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "    model = torch.quantization.prepare_qat(model)\n",
        "    return model\n",
        "\n",
        "def convert_qat_model(model):\n",
        "    model = torch.quantization.convert(model.eval())\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_k_fold_split(X, y,A, k, num_splits=5):\n",
        "    indices = np.arange(len(X))\n",
        "    fold_size = len(X) // num_splits\n",
        "\n",
        "    start = k * fold_size\n",
        "    end = start + fold_size if k != num_splits - 1 else len(X)\n",
        "\n",
        "    test_idx = indices[start:end]\n",
        "    train_idx = np.concatenate([indices[:start], indices[end:]])\n",
        "\n",
        "    return X[train_idx], y[train_idx], A[train_idx], X[test_idx], y[test_idx], A[test_idx]\n",
        "\n",
        "\n",
        "def train_baseline_model(X_train, y_train, fold, num_epochs=10, batch_size=64):\n",
        "  model = NetArch2()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "  train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "      for batch_X, batch_y in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(batch_X)\n",
        "          loss = criterion(outputs, batch_y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  y_true, y_pred = [], []\n",
        "  with torch.no_grad():\n",
        "      for batch_X, batch_y in train_loader:\n",
        "          outputs = model(batch_X)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          y_true.extend(batch_y.numpy())\n",
        "          y_pred.extend(predicted.numpy())\n",
        "\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "  print(f\"Fold {fold + 1}: Train F1 Score = {f1:.4f}\")\n",
        "\n",
        "\n",
        "  model_path = f\"model_fold{fold}.pkl\"\n",
        "  save_model(model, model_path)\n",
        "\n",
        "  return model\n",
        "\n",
        "def train_qat_model(X_train, y_train, fold, num_epochs=10, batch_size=64):\n",
        "    model = QATArch2()\n",
        "    model = prepare_model_for_qat(model)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_X.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    quantized_model = convert_qat_model(model)\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            outputs = quantized_model(batch_X)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(batch_y.numpy())\n",
        "            y_pred.extend(predicted.numpy())\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"Fold {fold + 1}: Train F1 Score (QAT) = {f1:.4f}\")\n",
        "\n",
        "    model_path = f\"qat_model_fold{fold}.pkl\"\n",
        "    save_model(quantized_model, model_path)\n",
        "\n",
        "    return quantized_model\n",
        "\n",
        "\n",
        "def evaluate_baseline_model(model, X_test, y_test, A_test):\n",
        "    output = model.forward(torch.FloatTensor(X_test))\n",
        "    _, y_pred = torch.max(output, dim=1)\n",
        "\n",
        "    y_pred = pd.Series(y_pred.detach().numpy())\n",
        "    y_test = pd.Series(y_test)\n",
        "\n",
        "    mf1 = MetricFrame(metrics=f1_score, y_true=y_test, y_pred=y_pred, sensitive_features=A_test)\n",
        "\n",
        "    baseline_metrics = {\n",
        "        \"Baseline Statistical Parity Difference\": round(calculate_statistical_parity_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Baseline Average Odds Difference\": round(calculate_average_odds_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Baseline Disparate Impact\": round(calculate_disparate_impact(y_test, y_pred, A_test), 3),\n",
        "        \"Baseline Theil Index\": round(calculate_theil_index(y_test, y_pred),3),\n",
        "        \"Baseline Theil Index - Within\": round(theil_by_group(y_pred, A_test), 3),\n",
        "        \"Baseline F1 Score\": round(f1_score(y_test, y_pred),3)\n",
        "    }\n",
        "\n",
        "    return baseline_metrics\n",
        "\n",
        "def evaluate_qat_model(model, X_test, y_test, A_test):\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    nan_mask = np.isnan(X_test)\n",
        "    if nan_mask.any():\n",
        "        col_means = np.nanmean(X_test, axis=0)\n",
        "        X_test[nan_mask] = col_means[nan_mask[0]]\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(X_test_tensor)\n",
        "        _, y_pred = torch.max(output, dim=1)\n",
        "\n",
        "    y_pred_np = y_pred.cpu().numpy()\n",
        "\n",
        "    qat_metrics = {\n",
        "        \"QAT Statistical Parity Difference\": round(calculate_statistical_parity_difference(y_test, y_pred_np, A_test), 3),\n",
        "        \"QAT Average Odds Difference\": round(calculate_average_odds_difference(y_test, y_pred_np, A_test), 3),\n",
        "        \"QAT Disparate Impact\": round(calculate_disparate_impact(y_test, y_pred_np, A_test), 3),\n",
        "        \"QAT Theil Index\": round(calculate_theil_index(y_test, y_pred_np), 3),\n",
        "        \"QAT Theil Index-Within\": round(theil_by_group(y_pred_np, A_test), 3),\n",
        "        \"QAT F1 Score\": round(f1_score(y_test, y_pred_np), 3),\n",
        "    }\n",
        "\n",
        "    return qat_metrics\n",
        "\n",
        "def evaluate_compressed_model(model, X_test, y_test, A_test):\n",
        "    output = model(torch.FloatTensor(X_test))\n",
        "    _, y_pred = torch.max(output, dim=1)\n",
        "\n",
        "    y_pred = pd.Series(y_pred.detach().numpy())\n",
        "    y_test = pd.Series(y_test)\n",
        "\n",
        "    mf = MetricFrame(metrics=f1_score, y_true=y_test, y_pred=y_pred, sensitive_features=A_test)\n",
        "\n",
        "    compressed_metrics = {\n",
        "        \"Compressed Statistical Parity Difference\": round(calculate_statistical_parity_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Compressed Average Odds Difference\": round(calculate_average_odds_difference(y_test, y_pred, A_test), 3),\n",
        "        \"Compressed Disparate Impact\": round(calculate_disparate_impact(y_test, y_pred, A_test), 3),\n",
        "        \"Compressed Theil Index\": round(calculate_theil_index(y_test, y_pred), 3),\n",
        "        \"Compressed Theil Index-Within\": round(theil_by_group(y_pred, A_test), 3),\n",
        "        \"Compressed F1 Score\": round(f1_score(y_test, y_pred), 3),\n",
        "    }\n",
        "\n",
        "    return compressed_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k‑Fold Cross Validation\n"
      ],
      "metadata": {
        "id": "av1ZTFC200mE"
      },
      "id": "av1ZTFC200mE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kfold-crossvalidation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfold-crossvalidation",
        "outputId": "8ec08aae-5e31-41a9-cdec-9f9d600ce0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4328390a73c8>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y = y.replace({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1}).astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing fold 1/10\n",
            "Fold 1: Train F1 Score = 0.6982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: Train F1 Score (QAT) = 0.6821\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.17), 'Baseline Average Odds Difference': np.float64(0.099), 'Baseline Disparate Impact': np.float64(0.3), 'Baseline Theil Index': np.float64(-0.103), 'Baseline Theil Index - Within': group\n",
            "Female    2.619\n",
            "Male      1.416\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.647}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.198), 'Compressed Average Odds Difference': np.float64(0.11), 'Compressed Disparate Impact': np.float64(0.313), 'Compressed Theil Index': np.float64(-0.034), 'Compressed Theil Index-Within': group\n",
            "Female    2.410\n",
            "Male      1.247\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.674}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.163), 'QAT Average Odds Difference': np.float64(0.081), 'QAT Disparate Impact': np.float64(0.325), 'QAT Theil Index': np.float64(-0.101), 'QAT Theil Index-Within': group\n",
            "Female    2.544\n",
            "Male      1.420\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.641}\n",
            "\n",
            "Processing fold 2/10\n",
            "Fold 2: Train F1 Score = 0.7118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: Train F1 Score (QAT) = 0.6991\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.154), 'Baseline Average Odds Difference': np.float64(0.056), 'Baseline Disparate Impact': np.float64(0.336), 'Baseline Theil Index': np.float64(-0.101), 'Baseline Theil Index - Within': group\n",
            "Female    2.551\n",
            "Male      1.462\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.67}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.201), 'Compressed Average Odds Difference': np.float64(0.071), 'Compressed Disparate Impact': np.float64(0.342), 'Compressed Theil Index': np.float64(0.009), 'Compressed Theil Index-Within': group\n",
            "Female    2.259\n",
            "Male      1.188\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.689}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.161), 'QAT Average Odds Difference': np.float64(0.073), 'QAT Disparate Impact': np.float64(0.323), 'QAT Theil Index': np.float64(-0.094), 'QAT Theil Index-Within': group\n",
            "Female    2.567\n",
            "Male      1.437\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.658}\n",
            "\n",
            "Processing fold 3/10\n",
            "Fold 3: Train F1 Score = 0.7213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: Train F1 Score (QAT) = 0.7083\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.203), 'Baseline Average Odds Difference': np.float64(0.089), 'Baseline Disparate Impact': np.float64(0.281), 'Baseline Theil Index': np.float64(-0.043), 'Baseline Theil Index - Within': group\n",
            "Female    2.534\n",
            "Male      1.263\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.662}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.249), 'Compressed Average Odds Difference': np.float64(0.129), 'Compressed Disparate Impact': np.float64(0.272), 'Compressed Theil Index': np.float64(0.032), 'Compressed Theil Index-Within': group\n",
            "Female    2.375\n",
            "Male      1.072\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.683}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.179), 'QAT Average Odds Difference': np.float64(0.054), 'QAT Disparate Impact': np.float64(0.309), 'QAT Theil Index': np.float64(-0.073), 'QAT Theil Index-Within': group\n",
            "Female    2.526\n",
            "Male      1.351\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.669}\n",
            "\n",
            "Processing fold 4/10\n",
            "Fold 4: Train F1 Score = 0.7167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: Train F1 Score (QAT) = 0.6891\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.159), 'Baseline Average Odds Difference': np.float64(0.024), 'Baseline Disparate Impact': np.float64(0.402), 'Baseline Theil Index': np.float64(-0.047), 'Baseline Theil Index - Within': group\n",
            "Female    2.235\n",
            "Male      1.324\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.678}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.186), 'Compressed Average Odds Difference': np.float64(0.038), 'Compressed Disparate Impact': np.float64(0.413), 'Compressed Theil Index': np.float64(0.024), 'Compressed Theil Index-Within': group\n",
            "Female    2.034\n",
            "Male      1.149\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.687}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.177), 'QAT Average Odds Difference': np.float64(0.094), 'QAT Disparate Impact': np.float64(0.286), 'QAT Theil Index': np.float64(-0.096), 'QAT Theil Index-Within': group\n",
            "Female    2.646\n",
            "Male      1.396\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.657}\n",
            "\n",
            "Processing fold 5/10\n",
            "Fold 5: Train F1 Score = 0.7114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5: Train F1 Score (QAT) = 0.7062\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.181), 'Baseline Average Odds Difference': np.float64(0.082), 'Baseline Disparate Impact': np.float64(0.302), 'Baseline Theil Index': np.float64(-0.08), 'Baseline Theil Index - Within': group\n",
            "Female    2.548\n",
            "Male      1.351\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.685}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.286), 'Compressed Average Odds Difference': np.float64(0.149), 'Compressed Disparate Impact': np.float64(0.292), 'Compressed Theil Index': np.float64(0.092), 'Compressed Theil Index-Within': group\n",
            "Female    2.137\n",
            "Male      0.905\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.665}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.172), 'QAT Average Odds Difference': np.float64(0.067), 'QAT Disparate Impact': np.float64(0.332), 'QAT Theil Index': np.float64(-0.077), 'QAT Theil Index-Within': group\n",
            "Female    2.457\n",
            "Male      1.354\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.668}\n",
            "\n",
            "Processing fold 6/10\n",
            "Fold 6: Train F1 Score = 0.7059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 6: Train F1 Score (QAT) = 0.6744\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.18), 'Baseline Average Odds Difference': np.float64(0.088), 'Baseline Disparate Impact': np.float64(0.283), 'Baseline Theil Index': np.float64(-0.094), 'Baseline Theil Index - Within': group\n",
            "Female    2.645\n",
            "Male      1.383\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.667}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.215), 'Compressed Average Odds Difference': np.float64(0.116), 'Compressed Disparate Impact': np.float64(0.268), 'Compressed Theil Index': np.float64(-0.034), 'Compressed Theil Index-Within': group\n",
            "Female    2.545\n",
            "Male      1.227\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.69}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.161), 'QAT Average Odds Difference': np.float64(0.089), 'QAT Disparate Impact': np.float64(0.28), 'QAT Theil Index': np.float64(-0.139), 'QAT Theil Index-Within': group\n",
            "Female    2.766\n",
            "Male      1.495\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.634}\n",
            "\n",
            "Processing fold 7/10\n",
            "Fold 7: Train F1 Score = 0.7141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 7: Train F1 Score (QAT) = 0.7045\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.16), 'Baseline Average Odds Difference': np.float64(0.065), 'Baseline Disparate Impact': np.float64(0.379), 'Baseline Theil Index': np.float64(-0.074), 'Baseline Theil Index - Within': group\n",
            "Female    2.329\n",
            "Male      1.358\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.658}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.209), 'Compressed Average Odds Difference': np.float64(0.102), 'Compressed Disparate Impact': np.float64(0.365), 'Compressed Theil Index': np.float64(0.022), 'Compressed Theil Index-Within': group\n",
            "Female    2.121\n",
            "Male      1.113\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.673}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.185), 'QAT Average Odds Difference': np.float64(0.105), 'QAT Disparate Impact': np.float64(0.31), 'QAT Theil Index': np.float64(-0.069), 'QAT Theil Index-Within': group\n",
            "Female    2.488\n",
            "Male      1.318\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.657}\n",
            "\n",
            "Processing fold 8/10\n",
            "Fold 8: Train F1 Score = 0.7184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 8: Train F1 Score (QAT) = 0.6948\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.2), 'Baseline Average Odds Difference': np.float64(0.122), 'Baseline Disparate Impact': np.float64(0.264), 'Baseline Theil Index': np.float64(-0.057), 'Baseline Theil Index - Within': group\n",
            "Female    2.637\n",
            "Male      1.304\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.672}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.224), 'Compressed Average Odds Difference': np.float64(0.147), 'Compressed Disparate Impact': np.float64(0.25), 'Compressed Theil Index': np.float64(-0.021), 'Compressed Theil Index-Within': group\n",
            "Female    2.596\n",
            "Male      1.209\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.683}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.168), 'QAT Average Odds Difference': np.float64(0.078), 'QAT Disparate Impact': np.float64(0.308), 'QAT Theil Index': np.float64(-0.094), 'QAT Theil Index-Within': group\n",
            "Female    2.596\n",
            "Male      1.417\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.657}\n",
            "\n",
            "Processing fold 9/10\n",
            "Fold 9: Train F1 Score = 0.7204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 9: Train F1 Score (QAT) = 0.7091\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.185), 'Baseline Average Odds Difference': np.float64(0.077), 'Baseline Disparate Impact': np.float64(0.305), 'Baseline Theil Index': np.float64(-0.05), 'Baseline Theil Index - Within': group\n",
            "Female    2.508\n",
            "Male      1.321\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.67}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.225), 'Compressed Average Odds Difference': np.float64(0.093), 'Compressed Disparate Impact': np.float64(0.331), 'Compressed Theil Index': np.float64(0.046), 'Compressed Theil Index-Within': group\n",
            "Female    2.195\n",
            "Male      1.090\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.686}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.168), 'QAT Average Odds Difference': np.float64(0.045), 'QAT Disparate Impact': np.float64(0.367), 'QAT Theil Index': np.float64(-0.042), 'QAT Theil Index-Within': group\n",
            "Female    2.330\n",
            "Male      1.327\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.665}\n",
            "\n",
            "Processing fold 10/10\n",
            "Fold 10: Train F1 Score = 0.7196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 10: Train F1 Score (QAT) = 0.7010\n",
            "Baseline Eval: {'Baseline Statistical Parity Difference': np.float64(0.168), 'Baseline Average Odds Difference': np.float64(0.055), 'Baseline Disparate Impact': np.float64(0.353), 'Baseline Theil Index': np.float64(-0.063), 'Baseline Theil Index - Within': group\n",
            "Female    2.388\n",
            "Male      1.346\n",
            "Name: value, dtype: float64, 'Baseline F1 Score': 0.678}\n",
            "Compressed Eval: {'Compressed Statistical Parity Difference': np.float64(0.21), 'Compressed Average Odds Difference': np.float64(0.086), 'Compressed Disparate Impact': np.float64(0.358), 'Compressed Theil Index': np.float64(0.028), 'Compressed Theil Index-Within': group\n",
            "Female    2.147\n",
            "Male      1.120\n",
            "Name: value, dtype: float64, 'Compressed F1 Score': 0.674}\n",
            "QAT Eval: {'QAT Statistical Parity Difference': np.float64(0.175), 'QAT Average Odds Difference': np.float64(0.084), 'QAT Disparate Impact': np.float64(0.305), 'QAT Theil Index': np.float64(-0.085), 'QAT Theil Index-Within': group\n",
            "Female    2.569\n",
            "Male      1.381\n",
            "Name: value, dtype: float64, 'QAT F1 Score': 0.673}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X, y, A = load_your_dataset()\n",
        "num_splits = 10\n",
        "\n",
        "baseline_fold_metrics = []\n",
        "compressed_fold_metrics = []\n",
        "qat_fold_metrics = []\n",
        "\n",
        "for k in range(num_splits):\n",
        "    print(f\"\\nProcessing fold {k + 1}/{num_splits}\")\n",
        "\n",
        "    X_train, y_train, A_train, X_test, y_test, A_test = get_k_fold_split(X, y, A, k, num_splits)\n",
        "\n",
        "    baseline_model = train_baseline_model(X_train, y_train, k)\n",
        "    baseline_eval = evaluate_baseline_model(baseline_model, X_test, y_test, A_test)\n",
        "    model_path = f\"model_fold{k}.pkl\"\n",
        "\n",
        "    compressed_model = dynamic_compress_model(model_path)\n",
        "    compressed_eval = evaluate_compressed_model(compressed_model, X_test, y_test, A_test)\n",
        "\n",
        "    qat_model = train_qat_model(X_train, y_train, k)\n",
        "    qat_eval = evaluate_qat_model(qat_model, X_test, y_test, A_test)\n",
        "\n",
        "    baseline_fold_metrics.append(baseline_eval)\n",
        "    compressed_fold_metrics.append(compressed_eval)\n",
        "    qat_fold_metrics.append(qat_eval)\n",
        "\n",
        "    print(f\"Baseline Eval: {baseline_eval}\")\n",
        "    print(f\"Compressed Eval: {compressed_eval}\")\n",
        "    print(f\"QAT Eval: {qat_eval}\")\n",
        "\n",
        "baseline_df = pd.DataFrame(baseline_fold_metrics)\n",
        "compressed_df = pd.DataFrame(compressed_fold_metrics)\n",
        "qat_df = pd.DataFrame(qat_fold_metrics)\n",
        "\n",
        "\n",
        "baseline_df.to_csv(\"baseline_metrics.csv\", index=True, float_format=\"%.3f\")\n",
        "compressed_df.to_csv(\"compressed_metrics.csv\", index=True, float_format=\"%.3f\")\n",
        "qat_df.to_csv(\"qat_metrics.csv\", index=True, float_format=\"%.3f\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(baseline_df)\n",
        "baseline_df.to_csv(\"baseline_metrics.csv\", index=True, float_format=\"%.3f\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpVaPNTKKNk9",
        "outputId": "d78f14a2-89fe-4083-bdd4-dc32d83363f3"
      },
      "id": "VpVaPNTKKNk9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Baseline Statistical Parity Difference  Baseline Average Odds Difference  \\\n",
            "0                                   0.170                             0.099   \n",
            "1                                   0.154                             0.056   \n",
            "2                                   0.203                             0.089   \n",
            "3                                   0.159                             0.024   \n",
            "4                                   0.181                             0.082   \n",
            "5                                   0.180                             0.088   \n",
            "6                                   0.160                             0.065   \n",
            "7                                   0.200                             0.122   \n",
            "8                                   0.185                             0.077   \n",
            "9                                   0.168                             0.055   \n",
            "\n",
            "   Baseline Disparate Impact  Baseline Theil Index  \\\n",
            "0                      0.300                -0.103   \n",
            "1                      0.336                -0.101   \n",
            "2                      0.281                -0.043   \n",
            "3                      0.402                -0.047   \n",
            "4                      0.302                -0.080   \n",
            "5                      0.283                -0.094   \n",
            "6                      0.379                -0.074   \n",
            "7                      0.264                -0.057   \n",
            "8                      0.305                -0.050   \n",
            "9                      0.353                -0.063   \n",
            "\n",
            "                       Baseline Theil Index - Within  Baseline F1 Score  \n",
            "0  group\n",
            "Female    2.619\n",
            "Male      1.416\n",
            "Name: va...              0.647  \n",
            "1  group\n",
            "Female    2.551\n",
            "Male      1.462\n",
            "Name: va...              0.670  \n",
            "2  group\n",
            "Female    2.534\n",
            "Male      1.263\n",
            "Name: va...              0.662  \n",
            "3  group\n",
            "Female    2.235\n",
            "Male      1.324\n",
            "Name: va...              0.678  \n",
            "4  group\n",
            "Female    2.548\n",
            "Male      1.351\n",
            "Name: va...              0.685  \n",
            "5  group\n",
            "Female    2.645\n",
            "Male      1.383\n",
            "Name: va...              0.667  \n",
            "6  group\n",
            "Female    2.329\n",
            "Male      1.358\n",
            "Name: va...              0.658  \n",
            "7  group\n",
            "Female    2.637\n",
            "Male      1.304\n",
            "Name: va...              0.672  \n",
            "8  group\n",
            "Female    2.508\n",
            "Male      1.321\n",
            "Name: va...              0.670  \n",
            "9  group\n",
            "Female    2.388\n",
            "Male      1.346\n",
            "Name: va...              0.678  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9tEpQQ4eq1jL",
      "metadata": {
        "id": "9tEpQQ4eq1jL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "f9407abd-623a-4e8a-bea5-189fb510abb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.05.09/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.05.09/13.40.57.224020.log (deflated 92%)\n",
            "  adding: content/.config/logs/2025.05.09/13.41.27.718573.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.05.09/13.41.26.495445.log (deflated 87%)\n",
            "  adding: content/.config/logs/2025.05.09/13.41.18.092482.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.05.09/13.41.36.263788.log (deflated 57%)\n",
            "  adding: content/.config/logs/2025.05.09/13.41.36.930373.log (deflated 57%)\n",
            "  adding: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/default_configs.db (deflated 98%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/model_fold3.pkl (deflated 8%)\n",
            "  adding: content/model_fold9.pkl (deflated 8%)\n",
            "  adding: content/qat_model_fold0.pkl (deflated 23%)\n",
            "  adding: content/qat_model_fold8.pkl (deflated 23%)\n",
            "  adding: content/model_fold2.pkl (deflated 8%)\n",
            "  adding: content/baseline_metrics.csv (deflated 67%)\n",
            "  adding: content/qat_metrics.csv (deflated 68%)\n",
            "  adding: content/model_fold1.pkl (deflated 8%)\n",
            "  adding: content/model_fold7.pkl (deflated 8%)\n",
            "  adding: content/model_fold0.pkl (deflated 8%)\n",
            "  adding: content/model_fold5.pkl (deflated 8%)\n",
            "  adding: content/qat_model_fold9.pkl (deflated 23%)\n",
            "  adding: content/qat_model_fold4.pkl (deflated 23%)\n",
            "  adding: content/model_fold4.pkl (deflated 8%)\n",
            "  adding: content/qat_model_fold2.pkl (deflated 23%)\n",
            "  adding: content/model_fold6.pkl (deflated 8%)\n",
            "  adding: content/model_fold8.pkl (deflated 8%)\n",
            "  adding: content/compressed_metrics.csv (deflated 67%)\n",
            "  adding: content/qat_model_fold6.pkl (deflated 23%)\n",
            "  adding: content/qat_model_fold1.pkl (deflated 23%)\n",
            "  adding: content/qat_model_fold7.pkl (deflated 23%)\n",
            "  adding: content/qat_model_fold5.pkl (deflated 23%)\n",
            "  adding: content/qat_model_fold3.pkl (deflated 23%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/README.md (deflated 39%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_96e98306-f5be-4901-8412-b2c1bc86a850\", \"colab_files.zip\", 8565831)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!zip -r colab_files.zip /content\n",
        "from google.colab import files\n",
        "files.download('colab_files.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}